---
title: "Hands-on Exercise 10"
description: |
 "In this hands-on exercise, I will learn to how to calibrate Spatial Interaction Models (SIM) by using GLM() of Base R. The use case is adapted from Modelling population flows using spatial interaction models by Adam Dennett."
author:
  - name: Niharika Avula 
    url: https://example.com/norajones
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
        toc: TRUE
        toc_depth: 2
---

```{r setup, include=FALSE, eval = TRUE, echo = TRUE, message = FALSE, error = FALSE, fig.retina = 3, cache= TRUE}
knitr::opts_chunk$set(echo = FALSE)
```

# 1. Overview

By the end to this hands-on exercise, the following will be covered:

* to import GIS polygon data into R and save them as simple feature data.frame and SpatialPolygonsDataFrame by using appropriate functions of sf package of R
* to compute distance matrix in R
* to import aspatial data into R and save it as a data.frame
* to integrate the imported data.frame with the distance matrix
* to calibrate Spatial Interaction Models by using glm() of R
* to assess the perfromance of the SIMs by computing Goodness-of-Fit statistics


# 2. Getting Started

## 2.1 The data

Two data sets will be used in this hands-on exercise, they are:

* [Greater Capital City Statistical Areas, Australia](https://www.abs.gov.au/websitedbs/censushome.nsf/home/factsheetsgeography/$file/Greater%20Capital%20City%20Statistical%20Area%20-%20Fact%20Sheet.pdf) . It is in geojson format.
* [Migration data from 2011 Australia Census](https://www.abs.gov.au/ausstats/abs@.nsf/ViewContent?readform&view=productsbytopic&Action=Expand&Num=5.5.5). It is in csv file format.

In the later sections, it will be shown how to fetch these data directly from their hosting repositories online.

## 2.2 Installing and loading R packages

The R packages needed for this exercise are as follows:

* **Spatial data handling:** sf, sp, geojsonio, stplanr
* **Attribute data handling:** tidyverse, especially readr and dplyr, reshape2,
* **Thematic mapping:** tmap
* **Statistical graphic:** ggplot2
* **Statistical analysis:** caret

```{r}
packages = c('tmap', 'tidyverse',
             'sp', 'caret','sf',
             'geojsonio', 'reshape2', 
             'broom','rgdal')

for(p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}
```

Due to s2 object class issue, we will use the order version (i.e. 0.9-8) of sf package instead of the latest version (i.e. 1.0-3). The code chunk below will be used the install the appropriate version.

```{r}
library(devtools)
install_version("sf", version= "0.9-8", repos= "http://cran.us.r-project.org")
```

```{r}
library(sf)
```

# 3. Data Import and Prepatation

## 3.1 Importing geospatial data into R environment

Downloading a copy of the Greater Capital City Statistical Areas boundary layer from a dropbox depository using geojson_read() of geojsonio package.

```{r}
Aus <- geojson_read("https://www.dropbox.com/s/0fg80nzcxcsybii/GCCSA_2016_AUST_New.geojson?raw=1", what = "sp")
```

Next, extract the data by using the code chunk below

```{r}
Ausdata <- Aus@data
```

## 3.2 Convert to sf object and set CRS

The original data is in geojson format which needs to be converted into a ‘simple features’ object and set the coordinate reference system at the same time in case the file doesn’t have one.

```{r}
AusSF <- st_as_sf(Aus) %>% 
  st_set_crs(4283) 
```

## 3.3 Check and fix validity of simple features

Next, check if all the simple features are valid by using the code chunk below.

```{r}
st_is_valid(AusSF)
```

The output shows that there are several invalid features which needs to be fixed

```{r}
st_make_valid(AusSF)
```

```{r}
st_is_valid(AusSF)
```

## 3.4 Displaying boundary layer

It is good practice to plot the data and check if the boundary layer is correct. The code chunk below is used to plot AusSF simple feature data.frame by using qtm() of tmap package.

```{r}
tmap_mode("plot")
tmap_options(check.and.fix = TRUE)
qtm(AusSF)
```

## 3.5 Displaying data table

Viewing the simple feature data.frame by using the code chunk below

```{r}
head(AusSF, 10)
```

With close examination, you may have noticed that the code order is a bit weird, so let’s fix that and reorder by using the code chunk below

```{r}
AusSF1 <- AusSF[order(AusSF$GCCSA_CODE),]
```

```{r}
head(AusSF1, 10)
```

## 3.6 Converting into sp object

```{r}
Aus <- as(AusSF1, "Spatial")
```

# 4. Calculating a distance matrix

In our spatial interaction model, space is one of the key predictor variables. In this example we will use a very simple Euclidean distance measure between the centroids of the Greater Capital City Statistical Areas as our measure of space.

**Caution note:** With some areas so huge, there are obvious potential issues with this (for example we could use the average distance to larger settlements in the noncity areas), however as this is just an example, we will proceed with a simple solution for now.

## 4.1 Re-projecting to projected coordinate system

The original data is in geographical coordinate system and the unit of measurement is in decimal degree, which is not appropriate for distance measurement. Before we compute the distance matrix, we will re-project the Aus into projected coordinate system by using spTransform() of sp package.

```{r}
AusProj <- sp::spTransform(Aus, sp::CRS("+proj=lcc +lat_0=0 +lon_0=134 +lat_1=-18 +lat_2=-36 +x_0=0
+y_0=0 +ellps=GRS80 +units=m +no_defs"))
summary(AusProj)
```

## 4.2 Computing distance matrix

Technically, st_distance() of sf package can be used to compute the distance matrix. However, that process takes much longer time to complete. In view of this, spDist() of sp package is used.

```{r}
dist <- spDists(AusProj)
dist 
```

## 4.3 Converting distance matrix into distance pair list

* In order to integrate the distance matrix with the migration flow data frame later, we need to transform the newly derived distance matrix into a 3-column distance values list.
* *melt()* of **reshape2** package is used to complete the task.
* We can also achieve the same task using pivot_longer() of dplyr package.

```{r}
distPair <- melt(dist)
head(distPair, 10)
```

## 4.4 Converting unit of measurement from m into km

The unit of measurement of Australia projected coordinate system is in metre. As a result, the values in the distance matrix are in metres too. The code chunk below is used to convert the distance values into kilometres.

```{r}
distPair$value <- distPair$value / 1000
head(distPair, 10)
```

# 5. Importing Interaction Data

```{r}
mdata <- read_csv("https://www.dropbox.com/s/wi3zxlq5pff1yda/AusMig2011.csv?raw=1",col_names = TRUE)
glimpse(mdata)
```

## 5.1 Combining the imported migration data

* We now need to add in our distance data generated earlier and create a new column of total flows which excludes flows that occur within areas.
* we could keep the within-area (intra-area) flows, but they can cause problems so we will just exclude them for now.
* We first create a new total flows column which excludes intra-zone flow totals.
* We will set them to a very very small number to avoid making the intra-zonal distance become 0.

```{r}
mdata$FlowNoIntra <- ifelse(mdata$Orig_code == mdata$Dest_code,0,mdata$Flow)
mdata$offset <- ifelse(mdata$Orig_code == mdata$Dest_code,0.0000000001,1)
```

Next, we ordered our spatial data earlier so that our zones are in their code order. We can now easily join these data together with our flow data as they are in the correct order.

```{r}
mdata$dist <- distPair$value 
```

and while we are here, rather than setting the intra-zonal distances to 0, we should set them to something small (most intrazonal moves won’t occur over 0 distance)

```{r}
mdata$dist <- ifelse(mdata$dist == 0,5,mdata$dist)
```

Let’s have a quick look at what your spangly new data looks like:

```{r}
glimpse(mdata)
```

# 6. Visualising with desire line

In this section, we will learn how to prepare a desire line by using stplanr package.

## 6.1 Removing intra-zonal flows

We will not be plotting the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.

```{r}
mdatasub <- mdata[mdata$Orig_code!=mdata$Dest_code,]
```

First, use the od2line() function stplanr package to remove all but the origin, destination and flow columns.

```{r}
devtools::install_github("ropensci/stplanr")
library(stplanr)
```

```{r}
mdatasub_skinny <- mdatasub[,c(2,4,5)]
travel_network <- od2line(flow = mdatasub_skinny, 
                          zones = Aus)
```

Next, convert the flows to WGS84 projection.

```{r}
travel_networkwgs <- spTransform(travel_network, sp::CRS("+proj=longlat +datum=WGS84 +no_defs"))
```

Repeat the step for the Aus layer.


```{r}
AusWGS <- spTransform(Aus, sp::CRS("+proj=longlat +datum=WGS84 +no_defs"))
```

Lastly, we will set the line widths to some sensible value according to the flow.

```{r}
w <- mdatasub_skinny$Flow / max(mdatasub_skinny$Flow) * 10
```

Now, we are ready to plot the desire line map by using the code chunk below.

```{r}
plot(travel_networkwgs, lwd = w)
plot(AusWGS, add=T)
```

# 7. Building Spatial Interaction Models

It is time for us to learn how to using R Stat function to calibrate the Spatial Interaction Models. Instead of using lm() the glm() function will be used. This is because glm() allow us to calibrate the model using generalised linear regression methods.

Note: Section 2.2.2 of Modelling population flows using spatial interaction models provides a detail discussion of generalised linear regression modelling framework.

## 7.1 Unconstrained Spatial Interaction Model

In this section, we will calibrate an unconstrained spatial interaction model by using glm(). The explanatory variables are origin population (i.e. vi1_origpop), destination median income (i.e. wj3_destmedinc) and distance between origin and destination in km (i.e. dist).

```{r}
uncosim <- glm(Flow ~ log(vi1_origpop)+log(wj3_destmedinc)+log(dist), na.action = na.exclude, family = poisson(link = "log"), data = mdatasub)
summary(uncosim)
```
The model output report shows that the parameter estimates of the explanatory variables are significant at alpha value 0.001.

### 7.1.1 Fitting the model

To assess the performance of the model, we will use the fitted() of R to compute the fitted values.

```{r}
mdatasub$fitted <- fitted(uncosim)
```

### 7.1.2 The more difficult ways (optional)

Another way to calculate the estimates is to plug all of the parameters back into Equation 6 like this:

First, assign the parameter values from the model to the appropriate variables

```{r}
k <- uncosim$coefficients[1]
mu <- uncosim$coefficients[2]
alpha <- uncosim$coefficients[3]
beta <- -uncosim$coefficients[4]
```

Next, plug everything back into the Equation 6 model… (be careful with the positive and negative signing of the parameters as the beta parameter may not have been saved as negative so will need to force negative)

```{r}
mdatasub$unconstrainedEst2 <- exp(k+(mu*log(mdatasub$vi1_origpop))+(alpha*log(mdatasub$wj3_destmedinc))-(beta*log(mdatasub$dist)))
```

which is exactly the same as this

```{r}
mdatasub$unconstrainedEst2 <- (exp(k)*exp(mu*log(mdatasub$vi1_origpop))*exp(alpha*log(mdatasub$wj3_destmedinc))*exp(-beta*log(mdatasub$dist)))
```

### 7.1.3 Saving the fitted values

Now, we will run the model and save all of the new flow estimates in a new column in the dataframe.

```{r}
mdatasub$unconstrainedEst2 <- round(mdatasub$unconstrainedEst2,0)
sum(mdatasub$unconstrainedEst2)
```

Next, we will turn the output into a little matrix by using dcast() of maditr package.

```{r}
mdatasubmat2 <- dcast(mdatasub, Orig_code ~ Dest_code, sum, value.var = "unconstrainedEst2", margins=c("Orig_code", "Dest_code"))
mdatasubmat2
```

and compare with the original matrix by using the code chunk below.

```{r}
mdatasubmat <- dcast(mdatasub, Orig_code ~ Dest_code, sum, value.var = "Flow", margins=c("Orig_code", "Dest_code"))
mdatasubmat
```

We can also visualise the actual flow and estimated flow by scatter plot technique.

```{r}
ggplot(data=mdatasub, 
       aes(y = `Flow`, 
           x = `unconstrainedEst2`))+
  geom_point(color="black", fill="light blue")
```

### 7.1.4 Assessing the model performance

To provide a more formal assessment of the model, Goodness-o-Fit statistics will be used. The code chunk below uses postReSample() of caret package to compute three Goodness-of-Fit statistics.

```{r}
postResample(mdatasub$Flow,mdatasub$unconstrainedEst2)
```

Notice that the R-squared value of 0.32 is relatively low. It seems that the uncontrained model failed to fit the empirical data well.

## 7.2 Origin Constrained Spatial Interaction Model

In this section, we will calibrate an origin constrained SIM (the “-1” indicates no intercept in the regression model) by using glm().

```{r}
origSim <- glm(Flow ~ Orig_code+log(wj3_destmedinc)+log(dist)-1, na.action = na.exclude, family = poisson(link = "log"), data = mdatasub)
#let's have a look at it's summary...
summary(origSim)
```

We can examine how the constraints hold for destinations this time.

Firstly, we will fitted the model and roundup the estimated values by using the code chunk below.

```{r}
mdatasub$origSimFitted <- round(fitted(origSim),0)
```

Next, we will used the step you had learned in previous section to create pivot table to turn paired list into matrix.

```{r}
mdatasubmat3 <- dcast(mdatasub, Orig_code ~ Dest_code, sum, value.var = "origSimFitted", margins=c("Orig_code", "Dest_code"))
mdatasubmat3
```

You can then compare with the original observed data as shown below.

```{r}
mdatasubmat
```

Next, let us display the actual flow and estimated flow by using the scatter plot technique.

```{r}
ggplot(data=mdatasub, 
       aes(y = `Flow`, 
           x = `origSimFitted`))+
  geom_point(color="black", fill="light blue")
```

Lastly, we compare the fitted values and the actual values by computing Goodness-of-fit statistics

```{r}
postResample(mdatasub$Flow,mdatasub$origSimFitted)
```
Notice that the R-squared improved considerably from 0.32 in the unconstrained model to 0.43 in this origin constrained model.

## 7.3 Destination Constrained Spatial Interaction Model

In this section, we will calibrate a destination constrained SIM (the “-1” indicates no intercept in the regression model) by using glm().

```{r}
destSim <- glm(Flow ~ Dest_code+log(vi1_origpop)+log(dist)-1, na.action = na.exclude, family = poisson(link = "log"), data = mdatasub)
summary(destSim)
```

We can examine how the constraints hold for destinations this time. Firstly, we will fitted the model and roundup the estimated values by using the code chunk below.

```{r}
mdatasub$destSimFitted <- round(fitted(destSim),0)
```

Next, we will used the step you had learned in previous section to create pivot table to turn paired list into matrix.

```{r}
mdatasubmat6 <- dcast(mdatasub, Orig_code ~ Dest_code, sum, value.var = "destSimFitted", margins=c("Orig_code", "Dest_code"))
mdatasubmat6
```

Similar to the previous section, you can then compare with the original observed data as shown below.

```{r}
mdatasubmat
```

Next, let us display the actual flow and estimated flow by using the scatter plot technique.

```{r}
ggplot(data=mdatasub, 
       aes(y = `Flow`, 
           x = `destSimFitted`))+
  geom_point(color="black", fill="light blue")
```

Finally, we can test the Goodness-of-Fit in exactly the same way as before:

```{r}
postResample(mdatasub$Flow,mdatasub$destSimFitted)
```

## 7.4 Doubly Constrained Spatial Interaction Model

In this section, we will calibrate a Doubly Constrained Spatial Interaction Model by using glm().

```{r}
doubSim <- glm(Flow ~ Orig_code+Dest_code+log(dist), na.action = na.exclude, family = poisson(link = "log"), data = mdatasub)
summary(doubSim)
```

We can examine how the constraints hold for destinations this time. Firstly, we will fitted the model and roundup the estimated values by using the code chunk below.

```{r}
mdatasub$doubsimFitted <- round(fitted(doubSim),0)
```

Next, we will used the step you had learned in previous section to create pivot table to turn paired list into matrix.

```{r}
mdatasubmat7 <- dcast(mdatasub, Orig_code ~ Dest_code, sum, value.var = "doubsimFitted", margins=c("Orig_code", "Dest_code"))
mdatasubmat7
```

Similar to the previous section, you can then compare with the original observed data as shown below.

```{r}
mdatasubmat
```

Next, let us display the actual flow and estimated flow by using the scatter plot technique.

```{r}
ggplot(data=mdatasub, 
       aes(y = `Flow`, 
           x = `doubsimFitted`))+
  geom_point(color="black", fill="light blue")
```

The scatter plot above reveals that the fitted values are highly correlated with the actual flow values. This show the Doubly Constrained Spatial Interaction Model is the best fit model among the four spatial interaction models.

To provide a quantitative assessment of the model, we can compute the Goodness-of-fit statistics exactly the same way as before.

```{r}
postResample(mdatasub$Flow,mdatasub$doubsimFitted)
```
The Goodness-of-fit statistics reveal that the Doubly Constrained Spatial Interaction Model is the best model because it produces the best R-squared statistic and smallest RMSE.

